---
title: 系统集成与测试
epic: search-log-manage
created: 2025-09-27T02:07:15Z
updated: 2025-09-27T08:51:58Z
estimate: 2-3天
parallel: true
depends_on: [003, 007]
status: in_progress
---

# 008 - 系统集成与测试

## 任务描述

完成搜索日志管理功能的系统集成和全面测试，包括性能监控、数据清理机制、完整的集成测试和部署配置。确保日志管理功能稳定可靠地集成到现有系统中，不影响搜索服务的正常运行。

## 验收标准

### 系统集成要求
- [ ] 完成前后端功能集成测试
- [ ] 验证AOP日志记录性能影响（<5%）
- [ ] 实现搜索日志数据清理机制
- [ ] 配置生产环境部署参数
- [ ] 建立监控和告警机制

### 功能测试要求
- [ ] 端到端测试覆盖主要场景
- [ ] 性能测试验证系统影响
- [ ] 负载测试验证系统稳定性
- [ ] 完善的错误处理和降级机制
- [ ] 数据清理功能正常运行

### 数据完整性要求
- [ ] 搜索日志记录完整性验证
- [ ] 点击行为数据一致性检查
- [ ] 数据清理不影响正常数据
- [ ] 异常场景下数据恢复机制

## 技术实施细节

### 1. 性能监控与优化

**文件路径：** `backend/src/main/java/com/ynet/mgmt/monitor/SearchLogMonitor.java`

**性能监控实现：**
```java
@Component
@ConditionalOnProperty(value = "search.log.monitor.enabled", havingValue = "true", matchIfMissing = true)
public class SearchLogMonitor {

    private static final Logger logger = LoggerFactory.getLogger(SearchLogMonitor.class);

    private final MeterRegistry meterRegistry;
    private final Counter searchLogRecords;
    private final Timer searchLogProcessingTime;
    private final Gauge searchLogQueueSize;

    @Autowired
    public SearchLogMonitor(MeterRegistry meterRegistry) {
        this.meterRegistry = meterRegistry;
        this.searchLogRecords = Counter.builder("search.log.records")
                .description("搜索日志记录总数")
                .register(meterRegistry);
        this.searchLogProcessingTime = Timer.builder("search.log.processing.time")
                .description("搜索日志处理时间")
                .register(meterRegistry);
        this.searchLogQueueSize = Gauge.builder("search.log.queue.size")
                .description("搜索日志队列大小")
                .register(meterRegistry, this, SearchLogMonitor::getQueueSize);
    }

    /**
     * 记录搜索日志处理指标
     */
    public void recordSearchLogMetrics(String operation, long duration, boolean success) {
        searchLogRecords.increment(
                Tags.of("operation", operation, "success", String.valueOf(success))
        );

        searchLogProcessingTime.record(duration, TimeUnit.MILLISECONDS);

        if (!success) {
            logger.warn("搜索日志操作失败: operation={}, duration={}ms", operation, duration);
        }
    }

    /**
     * 获取队列大小
     */
    private double getQueueSize() {
        return asyncTaskExecutor.getThreadPoolExecutor().getQueue().size();
    }

    /**
     * 监控搜索性能影响
     */
    @EventListener
    public void handleSearchCompleted(SearchCompletedEvent event) {
        Timer.Sample sample = Timer.start(meterRegistry);
        sample.stop(Timer.builder("search.performance.impact")
                .description("搜索性能影响监控")
                .register(meterRegistry));
    }

    /**
     * 健康检查端点
     */
    @GetMapping("/api/search-logs/health")
    public ResponseEntity<Map<String, Object>> healthCheck() {
        Map<String, Object> health = new HashMap<>();

        // 检查日志记录是否正常
        boolean logRecordingHealthy = checkLogRecordingHealth();

        // 检查数据库连接
        boolean databaseHealthy = checkDatabaseHealth();

        // 检查队列状态
        int queueSize = (int) getQueueSize();
        boolean queueHealthy = queueSize < 1000; // 队列大小正常

        health.put("logRecording", logRecordingHealthy ? "UP" : "DOWN");
        health.put("database", databaseHealthy ? "UP" : "DOWN");
        health.put("queue", queueHealthy ? "UP" : "DOWN");
        health.put("queueSize", queueSize);
        health.put("status", (logRecordingHealthy && databaseHealthy && queueHealthy) ? "UP" : "DOWN");

        return ResponseEntity.ok(health);
    }

    private boolean checkLogRecordingHealth() {
        // 检查最近5分钟是否有日志记录
        try {
            LocalDateTime fiveMinutesAgo = LocalDateTime.now().minusMinutes(5);
            long recentLogs = searchLogRepository.countByCreatedAtAfter(fiveMinutesAgo);
            return recentLogs > 0; // 有活跃的日志记录
        } catch (Exception e) {
            logger.error("检查日志记录健康状态失败", e);
            return false;
        }
    }

    private boolean checkDatabaseHealth() {
        try {
            searchLogRepository.count();
            return true;
        } catch (Exception e) {
            logger.error("数据库健康检查失败", e);
            return false;
        }
    }
}
```

### 2. 数据清理机制

**文件路径：** `backend/src/main/java/com/ynet/mgmt/searchlog/service/SearchLogCleanupService.java`

**数据清理实现：**
```java
@Service
@Transactional
public class SearchLogCleanupService {

    private static final Logger logger = LoggerFactory.getLogger(SearchLogCleanupService.class);

    @Autowired
    private SearchLogRepository searchLogRepository;

    @Autowired
    private ClickLogRepository clickLogRepository;

    @Value("${search.log.retention.days:30}")
    private int retentionDays;

    @Value("${search.log.cleanup.batch-size:1000}")
    private int batchSize;

    /**
     * 删除过期的搜索日志
     */
    @Scheduled(cron = "${search.log.cleanup.schedule:0 0 2 * * ?}")
    public void deleteExpiredLogs() {
        LocalDateTime cutoffDate = LocalDateTime.now().minusDays(retentionDays);

        logger.info("开始清理 {} 之前的搜索日志数据", cutoffDate);

        try {
            // 先删除关联的点击日志
            int deletedClicks = deleteExpiredClickLogs(cutoffDate);
            logger.info("清理过期点击日志: {} 条", deletedClicks);

            // 再删除搜索日志
            int deletedLogs = deleteExpiredSearchLogs(cutoffDate);
            logger.info("清理过期搜索日志: {} 条", deletedLogs);

            // 记录清理统计
            recordCleanupStats(deletedLogs, deletedClicks);

        } catch (Exception e) {
            logger.error("清理过期日志失败", e);
            throw new ServiceException("数据清理失败: " + e.getMessage());
        }
    }

    /**
     * 批量删除过期点击日志
     */
    private int deleteExpiredClickLogs(LocalDateTime cutoffDate) {
        int totalDeleted = 0;
        int batchDeleted;

        do {
            batchDeleted = clickLogRepository.deleteExpiredClickLogsBatch(cutoffDate, batchSize);
            totalDeleted += batchDeleted;

            if (batchDeleted > 0) {
                logger.debug("批量删除点击日志: {} 条", batchDeleted);
                // 避免长时间占用连接
                try {
                    Thread.sleep(100);
                } catch (InterruptedException e) {
                    Thread.currentThread().interrupt();
                    break;
                }
            }
        } while (batchDeleted > 0);

        return totalDeleted;
    }

    /**
     * 批量删除过期搜索日志
     */
    private int deleteExpiredSearchLogs(LocalDateTime cutoffDate) {
        int totalDeleted = 0;
        int batchDeleted;

        do {
            batchDeleted = searchLogRepository.deleteExpiredSearchLogsBatch(cutoffDate, batchSize);
            totalDeleted += batchDeleted;

            if (batchDeleted > 0) {
                logger.debug("批量删除搜索日志: {} 条", batchDeleted);
                try {
                    Thread.sleep(100);
                } catch (InterruptedException e) {
                    Thread.currentThread().interrupt();
                    break;
                }
            }
        } while (batchDeleted > 0);

        return totalDeleted;
    }

    /**
     * 记录清理统计
     */
    private void recordCleanupStats(int deletedLogs, int deletedClicks) {
        logger.info("数据清理完成 - 搜索日志: {}, 点击日志: {}", deletedLogs, deletedClicks);

        // 发送清理完成事件
        applicationEventPublisher.publishEvent(new DataCleanupCompletedEvent(
                deletedLogs, deletedClicks, LocalDateTime.now()
        ));
    }

    /**
     * 获取过期数据统计
     */
    public Map<String, Long> getExpiredDataStats() {
        LocalDateTime cutoffDate = LocalDateTime.now().minusDays(retentionDays);

        long expiredLogs = searchLogRepository.countExpiredLogs(cutoffDate);
        long expiredClicks = clickLogRepository.countExpiredClicks(cutoffDate);

        Map<String, Long> stats = new HashMap<>();
        stats.put("expiredLogs", expiredLogs);
        stats.put("expiredClicks", expiredClicks);
        stats.put("retentionDays", (long) retentionDays);

        return stats;
    }
}
```

### 3. 集成测试

**测试文件：** `backend/src/test/java/com/ynet/mgmt/searchlog/integration/SearchLogIntegrationTest.java`

**集成测试实现：**
```java
@SpringBootTest(webEnvironment = SpringBootTest.WebEnvironment.RANDOM_PORT)
@TestPropertySource(properties = {
        "search.log.enabled=true",
        "search.log.retention.days=7"
})
@Transactional
@Rollback
public class SearchLogIntegrationTest {

    @Autowired
    private TestRestTemplate restTemplate;

    @Autowired
    private SearchLogRepository searchLogRepository;

    @Autowired
    private ElasticsearchDataController elasticsearchController;

    @MockBean
    private ElasticsearchService elasticsearchService;

    @Test
    @DisplayName("完整的搜索日志记录流程测试")
    void testCompleteSearchLogFlow() {
        // 1. 执行搜索请求
        SearchDataRequest searchRequest = createSearchRequest();
        when(elasticsearchService.searchData(any())).thenReturn(createSearchResponse());

        ResponseEntity<ApiResponse> searchResponse = restTemplate.postForEntity(
                "/api/search-data",
                searchRequest,
                ApiResponse.class
        );

        assertThat(searchResponse.getStatusCode()).isEqualTo(HttpStatus.OK);

        // 2. 验证搜索日志已记录
        await().atMost(Duration.ofSeconds(5)).untilAsserted(() -> {
            List<SearchLog> logs = searchLogRepository.findByQuery(searchRequest.getQuery());
            assertThat(logs).hasSize(1);

            SearchLog log = logs.get(0);
            assertThat(log.getQuery()).isEqualTo(searchRequest.getQuery());
            assertThat(log.getStatus()).isEqualTo(SearchLogStatus.SUCCESS);
            assertThat(log.getResponseTime()).isGreaterThan(0);
        });

        // 3. 记录点击行为
        SearchLog savedLog = searchLogRepository.findByQuery(searchRequest.getQuery()).get(0);
        SearchClickRequest clickRequest = createClickRequest(savedLog.getId());

        ResponseEntity<ApiResponse> clickResponse = restTemplate.postForEntity(
                "/api/search-logs/clicks",
                clickRequest,
                ApiResponse.class
        );

        assertThat(clickResponse.getStatusCode()).isEqualTo(HttpStatus.OK);

        // 4. 验证点击记录
        await().atMost(Duration.ofSeconds(3)).untilAsserted(() -> {
            SearchLog updatedLog = searchLogRepository.findById(savedLog.getId()).orElseThrow();
            assertThat(updatedLog.getClickLogs()).hasSize(1);
        });
    }

    @Test
    @DisplayName("性能影响测试")
    void testPerformanceImpact() {
        // 禁用日志记录，测试基准性能
        System.setProperty("search.log.enabled", "false");
        long baselineTime = measureSearchPerformance();

        // 启用日志记录，测试性能影响
        System.setProperty("search.log.enabled", "true");
        long withLoggingTime = measureSearchPerformance();

        // 性能影响应该小于5%
        double performanceImpact = (double) (withLoggingTime - baselineTime) / baselineTime;
        assertThat(performanceImpact).isLessThan(0.05);

        logger.info("搜索性能影响: {}%", performanceImpact * 100);
    }

    @Test
    @DisplayName("数据清理测试")
    void testDataCleanup() {
        // 创建一些过期的测试数据
        createExpiredTestData();

        // 执行清理
        SearchLogCleanupService cleanupService = applicationContext.getBean(SearchLogCleanupService.class);
        cleanupService.deleteExpiredLogs();

        // 验证过期数据已被清理
        LocalDateTime cutoffDate = LocalDateTime.now().minusDays(7);
        long remainingLogs = searchLogRepository.countByCreatedAtBefore(cutoffDate);
        assertThat(remainingLogs).isEqualTo(0);
    }

    @Test
    @DisplayName("健康检查测试")
    void testHealthCheck() {
        ResponseEntity<Map> healthResponse = restTemplate.getForEntity(
                "/api/search-logs/health",
                Map.class
        );

        assertThat(healthResponse.getStatusCode()).isEqualTo(HttpStatus.OK);

        Map<String, Object> health = healthResponse.getBody();
        assertThat(health.get("status")).isEqualTo("UP");
        assertThat(health.get("database")).isEqualTo("UP");
    }

    @Test
    @DisplayName("错误处理测试")
    void testErrorHandling() {
        // 测试异常情况下的日志记录
        SearchDataRequest invalidRequest = new SearchDataRequest();
        invalidRequest.setQuery(null); // 无效请求

        when(elasticsearchService.searchData(any())).thenThrow(new RuntimeException("Search failed"));

        ResponseEntity<ApiResponse> response = restTemplate.postForEntity(
                "/api/search-data",
                invalidRequest,
                ApiResponse.class
        );

        // 验证错误日志已记录
        await().atMost(Duration.ofSeconds(3)).untilAsserted(() -> {
            List<SearchLog> errorLogs = searchLogRepository.findByStatus(SearchLogStatus.ERROR);
            assertThat(errorLogs).isNotEmpty();
        });
    }

    // 辅助方法
    private SearchDataRequest createSearchRequest() {
        SearchDataRequest request = new SearchDataRequest();
        request.setQuery("test query");
        request.setSearchSpaceId("test-space");
        return request;
    }

    private SearchDataResponse createSearchResponse() {
        SearchDataResponse response = new SearchDataResponse();
        response.setTotal(10);
        response.setResults(Collections.emptyList());
        return response;
    }

    private SearchClickRequest createClickRequest(Long searchLogId) {
        SearchClickRequest request = new SearchClickRequest();
        request.setSearchLogId(searchLogId);
        request.setDocumentId("doc1");
        request.setDocumentTitle("Test Document");
        request.setDocumentUrl("https://example.com/doc1");
        request.setClickPosition(1);
        return request;
    }

    private long measureSearchPerformance() {
        long startTime = System.currentTimeMillis();
        for (int i = 0; i < 100; i++) {
            SearchDataRequest request = createSearchRequest();
            try {
                elasticsearchController.searchData(request);
            } catch (Exception e) {
                // 忽略异常，专注于性能测试
            }
        }
        return System.currentTimeMillis() - startTime;
    }

    private void createExpiredTestData() {
        LocalDateTime expiredTime = LocalDateTime.now().minusDays(10);
        SearchLog expiredLog = new SearchLog();
        expiredLog.setQuery("expired query");
        expiredLog.setCreatedAt(expiredTime);
        searchLogRepository.save(expiredLog);
    }
}
```

### 4. 前端E2E测试

**测试文件：** `frontend/tests/e2e/searchLogManage.spec.ts`

**E2E测试实现：**
```typescript
import { test, expect } from '@playwright/test'

test.describe('搜索日志管理', () => {
  test('访问搜索日志管理页面', async ({ page }) => {
    // 导航到搜索日志管理页面
    await page.goto('/search-logs')
    await expect(page).toHaveURL('/search-logs')

    // 验证页面元素
    await expect(page.locator('h1')).toContainText('搜索日志管理')
    await expect(page.locator('[data-testid="search-log-table"]')).toBeVisible()
  })

  test('搜索日志筛选功能', async ({ page }) => {
    await page.goto('/search-logs')

    // 输入筛选条件
    await page.fill('[data-testid="filter-query"]', 'test')
    await page.selectOption('[data-testid="filter-status"]', 'SUCCESS')
    await page.click('[data-testid="filter-button"]')

    // 验证筛选结果
    await expect(page.locator('[data-testid="query-cell"]')).toContainText('test')
  })

  test('查看日志详情', async ({ page }) => {
    await page.goto('/search-logs')

    // 点击查看详情
    await page.click('[data-testid="view-detail-button"]')

    // 验证详情弹窗
    await expect(page.locator('[data-testid="detail-modal"]')).toBeVisible()
    await expect(page.locator('[data-testid="log-id"]')).toBeVisible()
    await expect(page.locator('[data-testid="request-params"]')).toBeVisible()
    await expect(page.locator('[data-testid="click-behavior"]')).toBeVisible()
  })

  test('点击行为记录功能', async ({ page }) => {
    await page.goto('/search')

    // 执行搜索
    await page.fill('[data-testid="search-input"]', 'test query')
    await page.click('[data-testid="search-button"]')

    // 等待搜索结果
    await expect(page.locator('[data-testid="search-results"]')).toBeVisible()

    // 点击搜索结果
    await page.click('[data-testid="result-item"]:first-child')

    // 验证点击行为被记录
    await page.goto('/search-logs')
    await page.fill('[data-testid="filter-query"]', 'test query')
    await page.click('[data-testid="filter-button"]')

    await page.click('[data-testid="view-detail-button"]:first-child')
    await expect(page.locator('[data-testid="click-logs"]')).toBeVisible()
  })

  test('多次点击记录功能', async ({ page }) => {
    await page.goto('/search')

    // 执行搜索
    await page.fill('[data-testid="search-input"]', 'multiple clicks')
    await page.click('[data-testid="search-button"]')

    // 等待搜索结果
    await expect(page.locator('[data-testid="search-results"]')).toBeVisible()

    // 点击第一个结果
    await page.click('[data-testid="result-item"]:nth-child(1)')

    // 返回并点击第二个结果
    await page.goBack()
    await page.click('[data-testid="result-item"]:nth-child(2)')

    // 验证多次点击记录
    await page.goto('/search-logs')
    await page.fill('[data-testid="filter-query"]', 'multiple clicks')
    await page.click('[data-testid="filter-button"]')

    await page.click('[data-testid="view-detail-button"]:first-child')
    const clickLogs = page.locator('[data-testid="click-log-item"]')
    await expect(clickLogs).toHaveCount(2)
  })

  test('系统性能监控页面', async ({ page }) => {
    await page.goto('/search-logs/monitor')

    // 验证监控页面元素
    await expect(page.locator('[data-testid="performance-metrics"]')).toBeVisible()
    await expect(page.locator('[data-testid="queue-status"]')).toBeVisible()
    await expect(page.locator('[data-testid="health-status"]')).toBeVisible()
  })
})
```

### 5. 部署配置

**文件路径：** `backend/src/main/resources/application-prod.yml`

**生产环境配置：**
```yaml
search:
  log:
    enabled: true
    retention:
      days: 90  # 生产环境保留90天
    cleanup:
      batch-size: 5000
      schedule: "0 0 3 * * ?"  # 每天凌晨3点清理
    async:
      core-pool-size: 4
      max-pool-size: 10
      queue-capacity: 1000
    monitor:
      enabled: true

spring:
  datasource:
    hikari:
      maximum-pool-size: 20
      minimum-idle: 5

management:
  endpoints:
    web:
      exposure:
        include: health,metrics,prometheus
  endpoint:
    health:
      show-details: always
  metrics:
    export:
      prometheus:
        enabled: true

logging:
  level:
    com.ynet.mgmt.searchlog: INFO
  pattern:
    file: "%d{yyyy-MM-dd HH:mm:ss} [%thread] %-5level %logger{36} - %msg%n"
```

**Docker配置更新：** `docker-compose.yml`
```yaml
version: '3.8'
services:
  backend:
    environment:
      - SEARCH_LOG_ENABLED=true
      - SEARCH_LOG_RETENTION_DAYS=90
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8080/api/search-logs/health"]
      interval: 30s
      timeout: 10s
      retries: 3
```

## 工作量估算

- **性能监控实现：** 0.5天
- **数据清理机制：** 0.5天
- **集成测试编写：** 1天
- **E2E测试编写：** 0.5天
- **部署配置和文档：** 0.5天
- **总计：** 2-3天

## 注意事项

1. **性能影响：** 持续监控对搜索服务的影响，确保<5%
2. **数据保护：** 合规的数据清理和脱敏处理
3. **可维护性：** 清晰的配置和监控机制
4. **稳定性：** 异常场景下的降级和恢复机制
5. **扩展性：** 为未来功能扩展预留空间

## 依赖关系

- **依赖任务：** 003 (AOP切面), 007 (前端界面)
- **完成目标：** 搜索日志管理功能完整上线

## 相关文件

- `SearchLogMonitor.java` - 性能监控
- `SearchLogCleanupService.java` - 数据清理
- `SearchLogIntegrationTest.java` - 集成测试
- `searchLogManage.spec.ts` - E2E测试
- `application-prod.yml` - 生产配置
- `docker-compose.yml` - 容器配置